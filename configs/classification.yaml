name: CiFAR-100-ViT-B-Pretrained
description: Classification on CiFAR-100 using pretrained ViT-B model
general:
  seed: 10
  backbone_name: "google/vit-base-patch16-224" # or None for random initialization
  wandb_project: "ViTRA"
  experiment_name: ${name}
  task: "classification"
  data_dir: "${hydra:runtime.cwd}/data"


optimizer:
  # Optimizer settings
  lr: 1e-5
  lr_gamma: 0.9
  momentum: 0.9
  optimizer_str: "sgd"
  batch_size_per_device: 512
  epochs: 15

  # Replicator settings
  replicate_every: 1
  skip_every: null
  shards: 2
  repl: "deto-demo"
  # Demo
  compression_topk: 1
  compression_chunk: 64
  # Random
  compression_rate: 0.5

distributed:
  nproc_per_node: 4
  nnodes: 1
  node_rank: 0
  master_addr: "localhost"
  master_port: 29500
  standalone: true # Setze auf false, wenn nnodes > 1

adversarial:
  enabled: true
  epsilon: 0.00392 # 1/255
  norm: "Linf"    
  batch_size_per_device: 512
  
  
